FROM apache/spark:3.5.0

ARG GCS_CONNECTOR_VERSION=2.2.5

USER root

# 기본 유틸
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# --- GCS Connector (shaded) ---
RUN curl -fL -o /opt/spark/jars/gcs-connector-hadoop3-${GCS_CONNECTOR_VERSION}-shaded.jar \
  https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-${GCS_CONNECTOR_VERSION}/gcs-connector-hadoop3-${GCS_CONNECTOR_VERSION}-shaded.jar \
  && chmod 644 /opt/spark/jars/gcs-connector-hadoop3-${GCS_CONNECTOR_VERSION}-shaded.jar \
  && rm -f /opt/spark/jars/gcs-connector-hadoop3-${GCS_CONNECTOR_VERSION}.jar \
  && echo "GCS connector installed:" \
  && ls -lah /opt/spark/jars | grep gcs

# --- JupyterLab ---
RUN pip install --no-cache-dir pyspark jupyterlab

# ✅ spark 사용자의 UID를 1000으로 변경 (호스트와 일치)
RUN usermod -u 1000 spark && groupmod -g 1000 spark

RUN mkdir -p /opt/spark/work \
  && chown -R spark:spark /opt/spark/work

# ✅ Jupyter / Spark / Ivy용 디렉토리 (컨테이너 전용 경로)
RUN mkdir -p \
    /home/spark/.jupyter/runtime \
    /home/spark/.jupyter/data \
    /home/spark/.ipython \
    /home/spark/.ivy2 \
 && chown -R 1000:1000 /home/spark

# ✅ HOME 기준 통일
ENV HOME=/home/spark

USER spark
WORKDIR /home/spark/work
